{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caf13084",
   "metadata": {},
   "source": [
    "# üìä Backtesting OpenSTEF Models with OpenSTEF-BEAM\n",
    "\n",
    "This tutorial demonstrates how to use **OpenSTEF-BEAM** (Backtesting, Evaluation, Analysis, Metrics) to systematically evaluate forecasting models. You'll learn how to:\n",
    "\n",
    "1. **Configure benchmark experiments** with multiple model types\n",
    "2. **Run parallel backtests** across dozens of energy assets\n",
    "3. **Compare model performance** with standardized metrics\n",
    "4. **Generate analysis reports** with interactive visualizations\n",
    "\n",
    "> **BEAM** provides a rigorous framework for model evaluation, ensuring fair comparisons and reproducible results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ce2a3",
   "metadata": {},
   "source": [
    "## üîß Environment Setup\n",
    "\n",
    "First, we configure thread settings to prevent conflicts with XGBoost's internal parallelization when running multiple processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d53eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Thread Configuration ---\n",
    "# Prevent thread contention when running parallel backtests with XGBoost\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# --- Standard Imports ---\n",
    "import logging\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(asctime)s][%(levelname)s] %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d9aed",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Benchmark Configuration\n",
    "\n",
    "Configure the benchmark parameters:\n",
    "- **Output paths** ‚Äî where to store results for each model\n",
    "- **Forecast horizons** ‚Äî how far ahead to predict (using ISO 8601 duration format)\n",
    "- **Quantiles** ‚Äî prediction intervals for probabilistic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c03b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import types for configuration\n",
    "from openstef_core.types import LeadTime, Q  # LeadTime: forecast horizon, Q: quantile\n",
    "from openstef_beam.benchmarking.benchmarks.liander2024 import Liander2024Category\n",
    "\n",
    "# --- Output Paths ---\n",
    "OUTPUT_PATH = Path(\"./benchmark_results\")\n",
    "BENCHMARK_RESULTS_PATH_XGBOOST = OUTPUT_PATH / \"XGBoost\"\n",
    "BENCHMARK_RESULTS_PATH_GBLINEAR = OUTPUT_PATH / \"GBLinear\"\n",
    "\n",
    "# --- Parallelization ---\n",
    "N_PROCESSES = multiprocessing.cpu_count()  # Use all available CPU cores\n",
    "print(f\"üñ•Ô∏è  Running with {N_PROCESSES} parallel processes\")\n",
    "\n",
    "# --- Forecast Configuration ---\n",
    "FORECAST_HORIZONS = [LeadTime.from_string(\"P3D\")]  # 3-day ahead forecast (ISO 8601: P3D)\n",
    "\n",
    "# Quantiles for probabilistic forecasting (7 quantiles covering 5th to 95th percentile)\n",
    "PREDICTION_QUANTILES = [\n",
    "    Q(0.05), Q(0.1), Q(0.3),  # Lower quantiles\n",
    "    Q(0.5),                    # Median\n",
    "    Q(0.7), Q(0.9), Q(0.95),  # Upper quantiles\n",
    "]\n",
    "\n",
    "# --- Benchmark Filter (optional) ---\n",
    "# Set to None to run all categories, or specify categories like:\n",
    "# BENCHMARK_FILTER = [Liander2024Category.TRANSFORMER, Liander2024Category.MV_FEEDER]\n",
    "BENCHMARK_FILTER: list[Liander2024Category] | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3618966",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Model Configuration\n",
    "\n",
    "We define a **common configuration** that both models share, then create model-specific variants. This ensures fair comparison by keeping all settings identical except the model type.\n",
    "\n",
    "### Available Models:\n",
    "- **XGBoost** ‚Äî Gradient boosting trees (handles complex nonlinear patterns)\n",
    "- **GBLinear** ‚Äî Gradient boosted linear model (better extrapolation, faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import workflow configuration\n",
    "from openstef_models.presets import ForecastingWorkflowConfig\n",
    "\n",
    "# Common configuration shared by all models\n",
    "# This ensures fair comparison by keeping all settings identical\n",
    "common_config = ForecastingWorkflowConfig(\n",
    "    model_id=\"benchmark_model_\",\n",
    "    run_name=None,\n",
    "    model=\"flatliner\",  # Placeholder - will be overwritten per model\n",
    "    \n",
    "    # Forecast settings\n",
    "    horizons=FORECAST_HORIZONS,\n",
    "    quantiles=PREDICTION_QUANTILES,\n",
    "    \n",
    "    # Model reuse: reuse trained model for same target (speeds up backtesting)\n",
    "    model_reuse_enable=True,\n",
    "    mlflow_storage=None,  # Disable MLflow for this demo\n",
    "    \n",
    "    # Weather feature column mappings (match dataset column names)\n",
    "    radiation_column=\"shortwave_radiation\",\n",
    "    wind_speed_column=\"wind_speed_80m\",  # 80m wind speed for better wind park predictions\n",
    "    pressure_column=\"surface_pressure\",\n",
    "    temperature_column=\"temperature_2m\",\n",
    "    relative_humidity_column=\"relative_humidity_2m\",\n",
    "    \n",
    "    # Additional features\n",
    "    energy_price_column=\"EPEX_NL\",  # Day-ahead electricity price\n",
    "    rolling_aggregate_features=[\"mean\", \"median\", \"max\", \"min\"],  # Rolling window stats\n",
    "    \n",
    "    # Logging\n",
    "    verbosity=0,  # Quiet mode for batch processing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed202922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model-specific configurations by copying common config and updating model type\n",
    "xgboost_config = common_config.model_copy(update={\"model\": \"xgboost\"})\n",
    "gblinear_config = common_config.model_copy(update={\"model\": \"gblinear\"})\n",
    "\n",
    "print(\"‚úÖ Model configurations created:\")\n",
    "print(f\"   - XGBoost: {xgboost_config.model}\")\n",
    "print(f\"   - GBLinear: {gblinear_config.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425a740",
   "metadata": {},
   "source": [
    "## üíæ Storage Configuration\n",
    "\n",
    "**LocalBenchmarkStorage** manages the file structure for benchmark results:\n",
    "```\n",
    "benchmark_results/\n",
    "‚îú‚îÄ‚îÄ XGBoost/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ backtest/      # Raw predictions\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ evaluation/    # Metrics per target\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ analysis/      # Visualizations (HTML)\n",
    "‚îî‚îÄ‚îÄ GBLinear/\n",
    "    ‚îî‚îÄ‚îÄ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e44656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage backends for each model\n",
    "from openstef_beam.benchmarking.storage.local_storage import LocalBenchmarkStorage\n",
    "\n",
    "storage_xgboost = LocalBenchmarkStorage(base_path=BENCHMARK_RESULTS_PATH_XGBOOST)\n",
    "storage_gblinear = LocalBenchmarkStorage(base_path=BENCHMARK_RESULTS_PATH_GBLINEAR)\n",
    "\n",
    "print(f\"üìÅ XGBoost results: {BENCHMARK_RESULTS_PATH_XGBOOST}\")\n",
    "print(f\"üìÅ GBLinear results: {BENCHMARK_RESULTS_PATH_GBLINEAR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e6b2e3",
   "metadata": {},
   "source": [
    "## üöÄ Run Backtests\n",
    "\n",
    "Now we run the **Liander 2024 Benchmark** ‚Äî a comprehensive evaluation suite that:\n",
    "1. Downloads the benchmark dataset from HuggingFace Hub (if needed)\n",
    "2. Runs backtests across 5 asset categories (transformers, feeders, solar/wind parks)\n",
    "3. Computes metrics and generates analysis visualizations\n",
    "\n",
    "‚ö†Ô∏è **Note**: This may take several minutes depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aae871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import benchmark components\n",
    "from openstef_beam.benchmarking.benchmarks.liander2024 import create_liander2024_benchmark_runner\n",
    "from openstef_beam.benchmarking.callbacks.strict_execution_callback import StrictExecutionCallback\n",
    "from openstef_beam.benchmarking.baselines import create_openstef4_preset_backtest_forecaster\n",
    "\n",
    "# --- Run XGBoost Benchmark ---\n",
    "print(\"üå≤ Running XGBoost benchmark...\")\n",
    "create_liander2024_benchmark_runner(\n",
    "    storage=storage_xgboost,\n",
    "    callbacks=[StrictExecutionCallback()],  # Fail fast on errors\n",
    ").run(\n",
    "    forecaster_factory=create_openstef4_preset_backtest_forecaster(\n",
    "        workflow_config=xgboost_config,\n",
    "    ),\n",
    "    run_name=\"xgboost\",\n",
    "    n_processes=N_PROCESSES,\n",
    "    filter_args=BENCHMARK_FILTER,\n",
    ")\n",
    "print(\"‚úÖ XGBoost benchmark complete!\")\n",
    "\n",
    "# --- Run GBLinear Benchmark ---\n",
    "print(\"\\nüìà Running GBLinear benchmark...\")\n",
    "create_liander2024_benchmark_runner(\n",
    "    storage=storage_gblinear,\n",
    "    callbacks=[StrictExecutionCallback()],\n",
    ").run(\n",
    "    forecaster_factory=create_openstef4_preset_backtest_forecaster(\n",
    "        workflow_config=gblinear_config,\n",
    "    ),\n",
    "    run_name=\"gblinear\",\n",
    "    n_processes=N_PROCESSES,\n",
    "    filter_args=BENCHMARK_FILTER,\n",
    ")\n",
    "print(\"‚úÖ GBLinear benchmark complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1690a07",
   "metadata": {},
   "source": [
    "## üìä Compare Model Performance\n",
    "\n",
    "The **BenchmarkComparisonPipeline** generates side-by-side analysis of multiple models:\n",
    "- Global metrics across all targets\n",
    "- Per-category breakdowns (transformers, feeders, etc.)\n",
    "- Time-windowed performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model comparison analysis\n",
    "from openstef_beam.benchmarking import BenchmarkComparisonPipeline\n",
    "from openstef_beam.benchmarking.benchmarks.liander2024 import LIANDER2024_ANALYSIS_CONFIG\n",
    "\n",
    "# Create comparison pipeline\n",
    "target_provider = create_liander2024_benchmark_runner(\n",
    "    storage=LocalBenchmarkStorage(base_path=OUTPUT_PATH),\n",
    ").target_provider\n",
    "\n",
    "comparison_pipeline = BenchmarkComparisonPipeline(\n",
    "    analysis_config=LIANDER2024_ANALYSIS_CONFIG,\n",
    "    storage=LocalBenchmarkStorage(base_path=OUTPUT_PATH),\n",
    "    target_provider=target_provider,\n",
    ")\n",
    "\n",
    "# Generate comparison reports\n",
    "print(\"üìä Generating comparison analysis...\")\n",
    "comparison_pipeline.run(run_data={\n",
    "    \"xgboost\": storage_xgboost,\n",
    "    \"gblinear\": storage_gblinear,\n",
    "})\n",
    "print(\"‚úÖ Comparison analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c61f4",
   "metadata": {},
   "source": [
    "## üìà View Analysis Results\n",
    "\n",
    "The benchmark generates interactive HTML visualizations. Let's open the most important ones:\n",
    "\n",
    "### Key Metrics:\n",
    "- **rCRPS** (relative Continuous Ranked Probability Score) ‚Äî measures probabilistic forecast accuracy\n",
    "- **rMAE** (relative Mean Absolute Error) ‚Äî measures point forecast accuracy\n",
    "- Lower values = better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open key analysis plots in browser\n",
    "# HTML visualizations are interactive and best viewed in a browser\n",
    "import webbrowser\n",
    "import os\n",
    "\n",
    "# Base path for analysis results\n",
    "analysis_base = os.path.abspath('./benchmark_results/analysis/D-1T06:00')\n",
    "\n",
    "# Define key visualizations to open\n",
    "visualizations = [\n",
    "    (\"rCRPS Grouped by Category\", \"rCRPS_grouped.html\"),\n",
    "    (\"rCRPS Time-Windowed (7 days)\", \"rCRPS_windowed_7D.html\"),\n",
    "]\n",
    "\n",
    "print(\"üåê Opening analysis visualizations in browser...\\n\")\n",
    "for name, filename in visualizations:\n",
    "    filepath = os.path.join(analysis_base, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"   üìä {name}\")\n",
    "        webbrowser.open(f'file://{filepath}')\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  {name} not found at {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8d779",
   "metadata": {},
   "source": [
    "### üîç Explore Individual Target Results\n",
    "\n",
    "You can also view time series plots for individual targets. Let's look at a transformer forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2fd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available target-specific visualizations\n",
    "import glob\n",
    "\n",
    "# Find all time series plots for individual targets\n",
    "target_plots = glob.glob('./benchmark_results/XGBoost/analysis/*/*/time_series_plot*.html')\n",
    "\n",
    "if target_plots:\n",
    "    print(\"üìä Available target-specific time series plots:\\n\")\n",
    "    for i, plot in enumerate(sorted(target_plots)[:5]):  # Show first 5\n",
    "        parts = plot.split('/')\n",
    "        category = parts[-3]  # e.g., \"transformer\"\n",
    "        target = parts[-2]    # e.g., \"OS Apeldoorn\"\n",
    "        print(f\"   {i+1}. {category}/{target}\")\n",
    "    \n",
    "    # Open the first transformer plot as an example\n",
    "    transformer_plots = [p for p in target_plots if 'transformer' in p]\n",
    "    if transformer_plots:\n",
    "        example_plot = os.path.abspath(transformer_plots[0])\n",
    "        print(f\"\\nüåê Opening example: {transformer_plots[0]}\")\n",
    "        webbrowser.open(f'file://{example_plot}')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No target-specific plots found. Run the benchmark first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41df479",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "1. ‚úÖ **Configure benchmark experiments** with `ForecastingWorkflowConfig`\n",
    "2. ‚úÖ **Run parallel backtests** using the Liander 2024 benchmark\n",
    "3. ‚úÖ **Compare models** (XGBoost vs GBLinear) with `BenchmarkComparisonPipeline`\n",
    "4. ‚úÖ **Analyze results** with interactive HTML visualizations\n",
    "\n",
    "### üìÅ Output Structure\n",
    "\n",
    "```\n",
    "benchmark_results/\n",
    "‚îú‚îÄ‚îÄ XGBoost/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ backtest/       # Raw predictions (parquet)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ evaluation/     # Metrics per target\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ analysis/       # HTML visualizations\n",
    "‚îú‚îÄ‚îÄ GBLinear/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ analysis/           # Comparison analysis (both models)\n",
    "    ‚îî‚îÄ‚îÄ D-1T06:00/\n",
    "        ‚îú‚îÄ‚îÄ rCRPS_grouped.html      # Probabilistic accuracy by category\n",
    "        ‚îú‚îÄ‚îÄ rMAE_grouped.html       # Point forecast accuracy\n",
    "        ‚îî‚îÄ‚îÄ summary.html            # Overall summary\n",
    "```\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "- Experiment with different `FORECAST_HORIZONS` (e.g., `\"PT6H\"`, `\"P7D\"`)\n",
    "- Add more quantiles for higher resolution prediction intervals\n",
    "- Filter specific categories with `BENCHMARK_FILTER`\n",
    "- Integrate MLflow for experiment tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
